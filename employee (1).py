# -*- coding: utf-8 -*-
"""Employee.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M5RJh0HE077g9IwX-ArvHSFXGoWNkiSb
"""

import pandas as pd

data = pd.read_csv("//content/adult 3 (2).csv")

data.head()

data.tail(7)

data.isna()

data.isna().sum()

print(data.occupation.value_counts())

print(data.gender.value_counts())

print(data.education.value_counts())

print(data['marital-status'].value_counts())

print(data['workclass'].value_counts())

print(data['native-country'].value_counts())

data.occupation.replace({'?':'Others'},inplace=True)

print(data['occupation'].value_counts())

data.workclass.replace({'?':'Notlisted'},inplace=True)

print(data['workclass'].value_counts())

data

data=data[data['workclass']!='without-pay']
data=data[data['workclass']!='Never-worked']

print(data['workclass'].value_counts())

data.shape

data=data[data['education']!='5th-6th']
data=data[data['education']!='1st-4th']
data=data[data['education']!='preschool']

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaled_cols = ['age']  # Add more numeric columns if needed
data[scaled_cols] = scaler.fit_transform(data[scaled_cols])
data







print(data['education'].value_counts())

data.shape

#redundacy
data.drop(columns=['education'],inplace=True)

data

#outlier
import matplotlib.pyplot as plt
plt.boxplot(data['age'])
plt.show()

data=data[(data['age']<=75) & (data['age']>=17)]

#outlier
plt.boxplot(data['age'])
plt.show()





#label encoading
from sklearn.preprocessing import LabelEncoder
encoder=LabelEncoder()
data['workclass']=encoder.fit_transform(data['workclass'])
data

x=data.drop(columns=['income'])
y=data['income']

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaled_cols = ['age']  # Add more numeric columns if needed
data[scaled_cols] = scaler.fit_transform(data[scaled_cols])
data

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaled_cols = ['age']  # Add more numeric columns if needed
data[scaled_cols] = scaler.fit_transform(data[scaled_cols])
data

print(data.columns)

['age', 'workclass', 'fnlwgt', 'education', 'educational-num', 'marital-status',
 'occupation', 'relationship', 'race', 'gender', 'capital-gain', 'capital-loss',
 'hours-per-week', 'native-country', 'income']

from sklearn.model_selection import train_test_split

# Drop the target column from features
X = data.drop(columns=['income'])

# Set the target variable
y = data['income']

# Split into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

data = pd.read_csv('/content/adult 3 (2).csv')  # replace with actual path
data.columns = data.columns.str.strip()  # clean column names

# Replace '?' with NaN
data.replace('?', np.nan, inplace=True)

# Drop rows with missing values
data.dropna(inplace=True)

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
binary_cols = ['gender', 'income']

for col in binary_cols:
    data[col] = le.fit_transform(data[col])

data = pd.get_dummies(data, columns=[
    'workclass', 'marital-status', 'occupation',
    'relationship', 'race', 'native-country'
], drop_first=True)

# Check for non-numeric columns
non_numeric = X.select_dtypes(include=['object']).columns
print("Non-numeric columns:", non_numeric)

# Drop target variable
X = data.drop(columns=['income'])

# Make sure all features are numeric
X = pd.get_dummies(X)  # Convert remaining categorical features to one-hot
y = data['income']     # Already label encoded

# Now apply feature scaling
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

print(X.dtypes)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

from sklearn.metrics import accuracy_score, classification_report

# KNN
knn_preds = knn.predict(X_test)
print("KNN Accuracy:", accuracy_score(y_test, knn_preds))
print(classification_report(y_test, knn_preds))

# Random Forest
rf_preds = rf.predict(X_test)
print("Random Forest Accuracy:", accuracy_score(y_test, rf_preds))
print(classification_report(y_test, rf_preds))

import joblib

joblib.dump(rf, 'best_model.pkl')  # assuming RF is better
joblib.dump(scaler, 'scaler.pkl')

X = pd.get_dummies(data.drop(columns=['income']))
feature_columns = X.columns  # Save for later use

# Scale
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Save scaler and model later

# Assuming this is done earlier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Train model
model = KNeighborsClassifier(n_neighbors=5)
model.fit(X_train, y_train)

# Predict
y_pred = model.predict(X_test)

# Accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

import matplotlib.pyplot as plt

# Bar Plot
plt.figure(figsize=(6, 4))
plt.bar(['KNN Classifier'], [accuracy], color='skyblue')
plt.ylim(0, 1)
plt.ylabel('Accuracy')
plt.title('Model Accuracy for Income Prediction')
plt.grid(axis='y')
plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()

# Classification Report
print(classification_report(y_test, y_pred))

from sklearn.metrics import accuracy_score

# Predictions
knn_preds = knn.predict(X_test)
rf_preds = rf.predict(X_test)

# Accuracy scores
knn_acc = accuracy_score(y_test, knn_preds)
rf_acc = accuracy_score(y_test, rf_preds)

import pandas as pd

accuracy_data = pd.DataFrame({
    'Classifier': ['KNN', 'Random Forest'],
    'Accuracy': [knn_acc, rf_acc]
})

!pip install streamlit

!pip install -q streamlit
!npm install -g localtunnel

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# 
# # Sample classifier results for demonstration
# data = pd.DataFrame({
#     "Classifier": ["KNN", "Random Forest"],
#     "Accuracy": [0.92, 0.95]  # Replace with your real values
# })
# 
# st.title("Classifier Accuracy Comparison")
# st.bar_chart(data.set_index("Classifier"))  # Bar chart
# 
# st.write("Demo complete!")  # Add your classification report output if you want
#

!streamlit run app.py &>/content/logs.txt &

!npx localtunnel --port 8501

!npx localtunnel --port 8501

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Splitting the dataset
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# KNN model training
model = KNeighborsClassifier(n_neighbors=5)
model.fit(X_train, y_train)

# Prediction
y_pred = model.predict(X_test)

# Accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Model Accuracy:", accuracy)

import matplotlib.pyplot as plt

plt.figure(figsize=(6, 4))
plt.bar(['KNN Classifier'], [accuracy], color='skyblue')
plt.ylim(0, 1)
plt.ylabel('Accuracy')
plt.title('Model Accuracy for Income Prediction')
plt.grid(axis='y')
plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()

from sklearn.metrics import classification_report

print("Classification Report:")
print(classification_report(y_test, y_pred))

# Required imports
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

# Split data (if not done already)
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Train KNN
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
knn_pred = knn.predict(X_test)
knn_acc = accuracy_score(y_test, knn_pred)

# Train Random Forest
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)
rf_pred = rf.predict(X_test)
rf_acc = accuracy_score(y_test, rf_pred)

# Print accuracies
print(f"KNN Accuracy: {knn_acc:.4f}")
print(f"Random Forest Accuracy: {rf_acc:.4f}")

# Accuracy comparison bar graph
models = ['KNN', 'Random Forest']
accuracies = [knn_acc, rf_acc]

plt.figure(figsize=(6, 4))
plt.bar(models, accuracies, color=['skyblue', 'orange'])
plt.ylim(0, 1)
plt.ylabel('Accuracy')
plt.title('Model Accuracy Comparison')
for i, acc in enumerate(accuracies):
    plt.text(i, acc + 0.01, f'{acc:.2f}', ha='center', fontsize=12)
plt.grid(axis='y')
plt.show()

import joblib

# Compare and store the best model
if rf_acc > knn_acc:
    best_model = rf
    print("Random Forest selected as the best model.")
else:
    best_model = knn
    print("KNN selected as the best model.")

# Save the best model
joblib.dump(best_model, 'best_model.joblib')
print("Best model saved as 'best_model.joblib'")

# Load the saved model
loaded_model = joblib.load('best_model.joblib')

# Predict on new data (e.g., after scaling)
# prediction = loaded_model.predict(new_df_scaled)

pip install streamlit

import streamlit as st
import pandas as pd
import numpy as np
import joblib

# Load model
model = joblib.load("best_model.joblib")

# UI title
st.title("Employee Salary Prediction App")

# Sidebar Inputs
st.sidebar.header("Enter Employee Details")

# Input fields (customize these based on your dataset's features)
age = st.sidebar.slider("Age", 18, 70, 30)
workclass = st.sidebar.selectbox("Workclass", ['Private', 'Self-emp-not-inc', 'Local-gov'])  # Example
education_num = st.sidebar.slider("Education Level (Num)", 1, 16, 10)
marital_status = st.sidebar.selectbox("Marital Status", ['Never-married', 'Married-civ-spouse'])  # Example
occupation = st.sidebar.selectbox("Occupation", ['Tech-support', 'Craft-repair'])  # Example
relationship = st.sidebar.selectbox("Relationship", ['Husband', 'Not-in-family'])  # Example
race = st.sidebar.selectbox("Race", ['White', 'Black'])  # Example
gender = st.sidebar.radio("Gender", ['Male', 'Female'])
hours_per_week = st.sidebar.slider("Hours per Week", 1, 100, 40)
capital_gain = st.sidebar.number_input("Capital Gain", value=0)
capital_loss = st.sidebar.number_input("Capital Loss", value=0)
native_country = st.sidebar.selectbox("Native Country", ['United-States', 'India'])  # Example

# One-hot encode or manually encode inputs
input_dict = {
    'age': age,
    'education-num': education_num,
    'capital-gain': capital_gain,
    'capital-loss': capital_loss,
    'hours-per-week': hours_per_week,
    # Dummy encoding or preprocessing must match the training time!
    'workclass': workclass,
    'marital-status': marital_status,
    'occupation': occupation,
    'relationship': relationship,
    'race': race,
    'gender': gender,
    'native-country': native_country
}

# Convert to DataFrame
input_df = pd.DataFrame([input_dict])

# You must apply same label encoding/one-hot encoding/scaling as you did in training
# You can load your scaler and encoders here if saved

st.subheader("Input Data Preview")
st.write(input_df)

# Predict
if st.button("Predict Income"):
    # Example: if you used a scaler in training, load and apply it
    # scaler = joblib.load('scaler.joblib')
    # input_scaled = scaler.transform(input_df)

    prediction = model.predict(input_df)
    st.success(f"Predicted Income Category: {prediction[0]}")

import streamlit as st
import pandas as pd
import joblib

# Load the trained model
model = joblib.load("best_model.pkl")

st.set_page_config(page_title="Employee Salary Classification", page_icon="💼", layout="centered")

st.title("💼 Employee Salary Classification App")
st.markdown("Predict whether an employee earns >50K or ≤50K based on input features.")

# Sidebar inputs (these must match your training feature columns)
st.sidebar.header("Input Employee Details")

# Replace these fields with your dataset's actual input columns
age = st.sidebar.slider("Age", 18, 65, 30)
education = st.sidebar.selectbox("Education Level", [
    "Bachelors", "Masters", "PhD", "HS-grad", "Assoc", "Some-college"
])
occupation = st.sidebar.selectbox("Job Role", [
    "Tech-support", "Craft-repair", "Other-service", "Sales",
    "Exec-managerial", "Prof-specialty", "Handlers-cleaners", "Machine-op-inspct",
    "Adm-clerical", "Farming-fishing", "Transport-moving", "Priv-house-serv",
    "Protective-serv", "Armed-Forces"
])
hours_per_week = st.sidebar.slider("Hours per week", 1, 80, 40)
experience = st.sidebar.slider("Years of Experience", 0, 40, 5)

# Build input DataFrame
input_df = pd.DataFrame({
    'age': [age],
    'education': [education],
    'occupation': [occupation],
    'hours-per-week': [hours_per_week],
    'experience': [experience]
})

st.write("### 🔎 Input Data")
st.write(input_df)

# Predict button
if st.button("Predict Salary Class"):
    prediction = model.predict(input_df)
    st.success(f"✅ Prediction: {prediction[0]}")

# Batch prediction
st.markdown("---")
st.markdown("#### 📂 Batch Prediction")
uploaded_file = st.file_uploader("Upload a CSV file for batch prediction", type="csv")

if uploaded_file is not None:
    batch_data = pd.read_csv(uploaded_file)
    st.write("Uploaded data preview:", batch_data.head())
    batch_preds = model.predict(batch_data)
    batch_data['PredictedClass'] = batch_preds
    st.write("✅ Predictions:")
    st.write(batch_data.head())
    csv = batch_data.to_csv(index=False).encode('utf-8')
    st.download_button("Download Predictions CSV", csv, file_name='predicted_classes.csv', mime='text/csv')

from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier

# Train KNN
knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train, y_train)

# Train Random Forest
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

from sklearn.metrics import accuracy_score

knn_pred = knn_model.predict(X_test)
rf_pred = rf_model.predict(X_test)

knn_acc = accuracy_score(y_test, knn_pred)
rf_acc = accuracy_score(y_test, rf_pred)

print("KNN Accuracy:", knn_acc)
print("Random Forest Accuracy:", rf_acc)

import joblib

if knn_acc > rf_acc:
    joblib.dump(knn_model, "best_model.pkl")
    print("KNN model saved as best_model.pkl")
else:
    joblib.dump(rf_model, "best_model.pkl")
    print("Random Forest model saved as best_model.pkl")

import joblib

if knn_acc > rf_acc:
    joblib.dump(knn_model, "best_model.pkl")
    print("KNN model saved as best_model.pkl")
else:
    joblib.dump(rf_model, "best_model.pkl")
    print("Random Forest model saved as best_model.pkl")

import joblib
joblib.dump(knn_model, "best_model.pkl")  # or rf_model

# First-time setup
!pip install -q streamlit pyngrok

# Create the app file

# Commented out IPython magic to ensure Python compatibility.
# 
# %%writefile app.py
# # (Paste your Streamlit code here or from previous cells)
# 
# # Run the Streamlit app
# from pyngrok import ngrok
# 
# # Setup a tunnel to the streamlit port 8501
# public_url = ngrok.connect(port='8501')
# print(f"Streamlit app running at: {public_url}")
# 
# !streamlit run app.py &> /dev/null &
#



